{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <ins> Project 4 Twitter Sentiment<ins>\n",
    "\n",
    "## Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding\n",
    "\n",
    "Data is taken from [data.world](\"https://data.world/crowdflower/brands-and-product-emotions/workspace/file?filename=judge-1377884607_tweet_product_company.csv\"). According to their website \"Contributors evaluated tweets about multiple brands and products. The crowd was asked if the tweet expressed positive, negative, or no emotion towards a brand and/or product. If some emotion was expressed they were also asked to say which brand or product was the target of that emotion. Added: August 30, 2013 by Kent Cavender-Bares | Data Rows: 9093\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer, regexp_tokenize\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Preparation\n",
    "df = pd.read_csv(\"data/judge-1377884607_tweet_product_company.csv\", encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9088</th>\n",
       "      <td>Ipad everywhere. #SXSW {link}</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9089</th>\n",
       "      <td>Wave, buzz... RT @mention We interrupt your re...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9090</th>\n",
       "      <td>Google's Zeiger, a physician never reported po...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9091</th>\n",
       "      <td>Some Verizon iPhone customers complained their...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9092</th>\n",
       "      <td>Ï¡Ïàü_ÊÎÒ£Áââ_£â_ÛâRT @...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9093 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             tweet_text  \\\n",
       "0     .@wesley83 I have a 3G iPhone. After 3 hrs twe...   \n",
       "1     @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
       "2     @swonderlin Can not wait for #iPad 2 also. The...   \n",
       "3     @sxsw I hope this year's festival isn't as cra...   \n",
       "4     @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n",
       "...                                                 ...   \n",
       "9088                      Ipad everywhere. #SXSW {link}   \n",
       "9089  Wave, buzz... RT @mention We interrupt your re...   \n",
       "9090  Google's Zeiger, a physician never reported po...   \n",
       "9091  Some Verizon iPhone customers complained their...   \n",
       "9092  Ï¡Ïàü_ÊÎÒ£Áââ_£â_ÛâRT @...   \n",
       "\n",
       "     emotion_in_tweet_is_directed_at  \\\n",
       "0                             iPhone   \n",
       "1                 iPad or iPhone App   \n",
       "2                               iPad   \n",
       "3                 iPad or iPhone App   \n",
       "4                             Google   \n",
       "...                              ...   \n",
       "9088                            iPad   \n",
       "9089                             NaN   \n",
       "9090                             NaN   \n",
       "9091                             NaN   \n",
       "9092                             NaN   \n",
       "\n",
       "     is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "0                                      Negative emotion  \n",
       "1                                      Positive emotion  \n",
       "2                                      Positive emotion  \n",
       "3                                      Negative emotion  \n",
       "4                                      Positive emotion  \n",
       "...                                                 ...  \n",
       "9088                                   Positive emotion  \n",
       "9089                 No emotion toward brand or product  \n",
       "9090                 No emotion toward brand or product  \n",
       "9091                 No emotion toward brand or product  \n",
       "9092                 No emotion toward brand or product  \n",
       "\n",
       "[9093 rows x 3 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9093 entries, 0 to 9092\n",
      "Data columns (total 3 columns):\n",
      " #   Column                                              Non-Null Count  Dtype \n",
      "---  ------                                              --------------  ----- \n",
      " 0   tweet_text                                          9092 non-null   object\n",
      " 1   emotion_in_tweet_is_directed_at                     3291 non-null   object\n",
      " 2   is_there_an_emotion_directed_at_a_brand_or_product  9093 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 213.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 5802 values that are missing in is there an emotion directed at a brand or product column, one missing in the first column which we will drop and 0 missing in the last column. In addition, there are many values that we will want to fill in as we go through data cleaning because they are mislabeled as neutral but contain an emotion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna(subset=['tweet_text'])\n",
    "df['tweet_text'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "Our first step will be tokenizing the first column, in order to do so we will need to convert our columns from object data types to strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweet_text'] = df['tweet_text'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# Checking to make sure new Dtype\n",
    "print(type(df['tweet_text'].iloc[13]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             tweet_text  \\\n",
      "0     .@wesley83 I have a 3G iPhone. After 3 hrs twe...   \n",
      "1     @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
      "2     @swonderlin Can not wait for #iPad 2 also. The...   \n",
      "3     @sxsw I hope this year's festival isn't as cra...   \n",
      "4     @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n",
      "...                                                 ...   \n",
      "9088                      Ipad everywhere. #SXSW {link}   \n",
      "9089  Wave, buzz... RT @mention We interrupt your re...   \n",
      "9090  Google's Zeiger, a physician never reported po...   \n",
      "9091  Some Verizon iPhone customers complained their...   \n",
      "9092  Ï¡Ïàü_ÊÎÒ£Áââ_£â_ÛâRT @...   \n",
      "\n",
      "                                           tweet_tokens  \n",
      "0     [., @wesley83, I, have, a, 3G, iPhone, ., Afte...  \n",
      "1     [@jessedee, Know, about, @fludapp, ?, Awesome,...  \n",
      "2     [@swonderlin, Can, not, wait, for, #iPad, 2, a...  \n",
      "3     [@sxsw, I, hope, this, year's, festival, isn't...  \n",
      "4     [@sxtxstate, great, stuff, on, Fri, #SXSW, :, ...  \n",
      "...                                                 ...  \n",
      "9088           [Ipad, everywhere, ., #SXSW, {, link, }]  \n",
      "9089  [Wave, ,, buzz, ..., RT, @mention, We, interru...  \n",
      "9090  [Google's, Zeiger, ,, a, physician, never, rep...  \n",
      "9091  [Some, Verizon, iPhone, customers, complained,...  \n",
      "9092  [, Ï, ¡, , Ïà, , ü_, , , Ê, , , Î, , ...  \n",
      "\n",
      "[9093 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Applying word token to tweet tokens\n",
    "df['tweet_tokens'] = df['tweet_text'].apply(tweet_tokenizer.tokenize)\n",
    "print(df[['tweet_text', 'tweet_tokens']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<class 'list'>]\n"
     ]
    }
   ],
   "source": [
    "print(df['tweet_tokens'].apply(type).unique())  # Should only show <class 'list'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gettings rid of stop words\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lower casing all tokens in tweet_tokens\n",
    "df['filtered'] = df['tweet_tokens'].apply(lambda tokens: [token.lower() for token in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [., @wesley83, i, have, a, 3g, iphone, ., afte...\n",
       "1    [@jessedee, know, about, @fludapp, ?, awesome,...\n",
       "2    [@swonderlin, can, not, wait, for, #ipad, 2, a...\n",
       "3    [@sxsw, i, hope, this, year's, festival, isn't...\n",
       "4    [@sxtxstate, great, stuff, on, fri, #sxsw, :, ...\n",
       "Name: filtered, dtype: object"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['filtered'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        tweet_tokens  \\\n",
      "0  [., @wesley83, I, have, a, 3G, iPhone, ., Afte...   \n",
      "1  [@jessedee, Know, about, @fludapp, ?, Awesome,...   \n",
      "2  [@swonderlin, Can, not, wait, for, #iPad, 2, a...   \n",
      "3  [@sxsw, I, hope, this, year's, festival, isn't...   \n",
      "4  [@sxtxstate, great, stuff, on, Fri, #SXSW, :, ...   \n",
      "\n",
      "                                     filtered_tokens  \n",
      "0  [., @wesley83, 3g, iphone, ., 3, hrs, tweeting...  \n",
      "1  [@jessedee, know, @fludapp, ?, awesome, ipad, ...  \n",
      "2  [@swonderlin, wait, #ipad, 2, also, ., sale, #...  \n",
      "3  [@sxsw, hope, year's, festival, crashy, year's...  \n",
      "4  [@sxtxstate, great, stuff, fri, #sxsw, :, mari...  \n"
     ]
    }
   ],
   "source": [
    "# Remove stopwords from the 'tweet_tokens' column\n",
    "df['filtered_tokens'] = df['filtered'].apply(\n",
    "    lambda tokens: [token for token in tokens if token not in stop_words]\n",
    ")\n",
    "\n",
    "# Check the result\n",
    "print(df[['tweet_tokens', 'filtered_tokens']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     filtered_tokens  \\\n",
      "0  [., @wesley83, 3g, iphone, ., 3, hrs, tweeting...   \n",
      "1  [@jessedee, know, @fludapp, ?, awesome, ipad, ...   \n",
      "2  [@swonderlin, wait, #ipad, 2, also, ., sale, #...   \n",
      "3  [@sxsw, hope, year's, festival, crashy, year's...   \n",
      "4  [@sxtxstate, great, stuff, fri, #sxsw, :, mari...   \n",
      "\n",
      "                                        clean_tokens  \n",
      "0  [wesley83, 3g, iphone, 3, hrs, tweeting, rise_...  \n",
      "1  [jessedee, know, fludapp, awesome, ipad, iphon...  \n",
      "2      [swonderlin, wait, ipad, 2, also, sale, sxsw]  \n",
      "3  [sxsw, hope, years, festival, crashy, years, i...  \n",
      "4  [sxtxstate, great, stuff, fri, sxsw, marissa, ...  \n"
     ]
    }
   ],
   "source": [
    "# Remove special characters from tokens\n",
    "df['clean_tokens'] = df['filtered_tokens'].apply(\n",
    "    lambda tokens: [re.sub(r'\\W+', '', token) for token in tokens if re.sub(r'\\W+', '', token)]\n",
    ")\n",
    "\n",
    "print(df[['filtered_tokens', 'clean_tokens']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.map_locations\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'pandas._libs.index.IndexEngine._call_map_locations'\n",
      "Traceback (most recent call last):\n",
      "  File \"pandas\\_libs\\hashtable_class_helper.pxi\", line 1709, in pandas._libs.hashtable.PyObjectHashTable.map_locations\n",
      "TypeError: unhashable type: 'list'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[rt, @mention, marissa, mayer, :, google, connect, digital, &, physical, worlds, mobile, -, {, link, }, #sxsw]                                             9\n",
       "[rt, @mention, google, launch, major, new, social, network, called, circles, ,, possibly, today, {, link, }, #sxsw]                                        9\n",
       "[win, free, ipad, 2, webdoc.com, #sxsw, rt]                                                                                                                7\n",
       "[google, launch, major, new, social, network, called, circles, ,, possibly, today, {, link, }, #sxsw]                                                      6\n",
       "[rt, @mention, rumor, :, apple, opening, temporary, store, downtown, austin, #sxsw, ipad, 2, launch, {, link, }]                                           4\n",
       "                                                                                                                                                          ..\n",
       "[watching, twit, live, #sxsw, ,, want, go, next, year, ., also, want, ipad, ,, i'm, content, wait, awhile, ., always, buy, technology, late, anyway, .]    1\n",
       "[rt, @mention, mashable, weekend, recap, :, 19, stories, may, missed, -, twitter, ,, android, #sxsw, {, link, }]                                           1\n",
       "[niche, product, party, i've, yet, !, google, sketchup, ., #sxsw, {, link, }]                                                                              1\n",
       "[rt, @mention, heard, apple's, pop-up, store, downtown, austin, ?, pics, already, gowalla, :, {, link, }, #sxsw, #ipad2]                                   1\n",
       "[#apple, #popupstore, #sxsw, ., get, #ipad, 0310apple, {, link, }]                                                                                         1\n",
       "Name: filtered_tokens, Length: 8983, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['filtered_tokens'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
